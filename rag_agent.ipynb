{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import VectorStoreIndex, SimpleDirectoryReader\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.core import StorageContext\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "from IPython.display import Markdown, display\n",
    "import chromadb\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# to load api key from .env file\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Vectorstore Database"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code snippet takes a whole folder of text files and creates a vectorstore based on it. With Machine Learning these are converted into numerical representation, so called embeddings. Embeddings are the numerical conversion of text in a multi-dimensional vector (room). Vectors (words) which are related to each other in meaning or context have a closer vector in the embedding vector. Consequently, the vectors are persisted in a vectorstore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e89e77b49df4c5d9e04c2ab13caf6a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Parsing nodes:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "52693e7b716b4807a1981f8bdf9e4ca0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Generating embeddings:   0%|          | 0/14 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# path of data folder\n",
    "data_folder = os.path.join(\"data\")\n",
    "\n",
    "\n",
    "# initializing ChromaDB\n",
    "db = chromadb.PersistentClient(path=\"chroma_db\")\n",
    "chroma_collection = db.get_or_create_collection(\"quickstart\")\n",
    "\n",
    "\n",
    "# define embedding function\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "\n",
    "# load documents\n",
    "documents = SimpleDirectoryReader(data_folder).load_data()\n",
    "\n",
    "\n",
    "# create and store vectors\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "\n",
    "index = VectorStoreIndex.from_documents(\n",
    "    documents, \n",
    "    storage_context=storage_context, \n",
    "    embed_model=embed_model,\n",
    "    show_progress=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Vectorstore Database and query it "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, the vectorstore is reloaded and the embeddings are reconstructed. Then it can be accessed for queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "<b>The document provides information on support measures and regulations related to combined transport in Austria, including exemptions from the night driving ban for noisy heavy goods vehicles with a maximum permissible gross weight of more than 7.5 tons. It also lists specific routes that are particularly relevant for combined transport in Austria.</b>"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# load from disk\n",
    "db2 = chromadb.PersistentClient(path=\"chroma_db\")\n",
    "chroma_collection = db2.get_or_create_collection(\"quickstart\")\n",
    "\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store,\n",
    "    embed_model=embed_model,\n",
    ")\n",
    "\n",
    "# Query Data from the persisted index\n",
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What is the document regarding combined transport in Austria about?\")\n",
    "display(Markdown(f\"<b>{response}</b>\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool note_engine for creating notes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the set up for the note engine which serves the agent as a tool for creating notes based on some results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.tools import FunctionTool\n",
    "import os\n",
    "from datetime import datetime\n",
    "import textwrap\n",
    "\n",
    "\n",
    "# file path where there notes.txt will be saved (in this case in same folder as this file)\n",
    "note_file = os.path.join(\"data\", \"notes.txt\")\n",
    "\n",
    "\n",
    "# function to create a notes.txt file based on input note\n",
    "def save_note(note):\n",
    "    if not os.path.exists(note_file):\n",
    "        open(note_file, \"w\")\n",
    "\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")    # gives the file additionally a time stamp\n",
    "\n",
    "    wrapped_note = textwrap.fill(note, width=80)                # to make breaks instead giving output into one single line\n",
    "\n",
    "    with open(note_file, \"a\") as f:\n",
    "        f.writelines([f\"[{timestamp}] {wrapped_note}\\n\"])\n",
    "\n",
    "    return \"note saved\"\n",
    "\n",
    "\n",
    "# creates a engine for the agent with the save_note function \n",
    "note_engine = FunctionTool.from_defaults(\n",
    "    fn = save_note,\n",
    "    name = \"note_saver\",\n",
    "    description = \"this tool saves a text based note to a file for the user\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent querying Database with tools"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This code combines loading vectorstore for querying, initializing and promping agent. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Running step d6009bd8-4626-49df-8fa8-66f9a6a3a0a7. Step input: which routes can you recommend me for a combined transport from vienna to italy?\n",
      "\u001b[1;3;38;5;200mThought: The current language of the user is: English. I need to use a tool to help me answer the question.\n",
      "Action: document_search\n",
      "Action Input: {'input': 'combined transport routes from Vienna to Italy'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: Wien Freudenau Hafen CCT – border crossing Nickelsdorf (Hungary)\n",
      "\u001b[0m> Running step 5c4de7a2-efcf-4849-b07f-46b2b571f16d. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I have found some information regarding a route from Vienna to Italy involving combined transport. However, I need to gather more details to provide a comprehensive answer.\n",
      "Action: document_search\n",
      "Action Input: {'input': 'combined transport options from Vienna to Italy'}\n",
      "\u001b[0m\u001b[1;3;34mObservation: The combined transport options from Vienna to Italy include the routes from Wien Freudenau Hafen CCT to border crossings in Nickelsdorf, Klingenbach, and Drasenhofen in Hungary, as well as the route from Brennersee to the border crossing Brenner in Italy.\n",
      "\u001b[0m> Running step ec049763-f391-4af0-aec1-0127699c5229. Step input: None\n",
      "\u001b[1;3;38;5;200mThought: I have gathered sufficient information about the combined transport routes from Vienna to Italy. I can now provide a comprehensive answer.\n",
      "Answer: For combined transport from Vienna to Italy, you can consider the following routes: \n",
      "\n",
      "1. From Wien Freudenau Hafen CCT to the border crossing in Nickelsdorf (Hungary).\n",
      "2. From Wien Freudenau Hafen CCT to the border crossing in Klingenbach (Hungary).\n",
      "3. From Wien Freudenau Hafen CCT to the border crossing in Drasenhofen (Hungary).\n",
      "4. From Brennersee to the border crossing Brenner in Italy. \n",
      "\n",
      "These routes facilitate efficient transport options between Vienna and various destinations in Italy.\n",
      "\u001b[0mFor combined transport from Vienna to Italy, you can consider the following routes: \n",
      "\n",
      "1. From Wien Freudenau Hafen CCT to the border crossing in Nickelsdorf (Hungary).\n",
      "2. From Wien Freudenau Hafen CCT to the border crossing in Klingenbach (Hungary).\n",
      "3. From Wien Freudenau Hafen CCT to the border crossing in Drasenhofen (Hungary).\n",
      "4. From Brennersee to the border crossing Brenner in Italy. \n",
      "\n",
      "These routes facilitate efficient transport options between Vienna and various destinations in Italy.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from llama_index.core.tools import QueryEngineTool, ToolMetadata\n",
    "from llama_index.core.agent import ReActAgent\n",
    "from llama_index.llms.openai import OpenAI\n",
    "from llama_index.core import VectorStoreIndex\n",
    "from llama_index.vector_stores.chroma import ChromaVectorStore\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "import chromadb\n",
    "import streamlit as st\n",
    "from note_engine import note_engine\n",
    "\n",
    "\n",
    "# to load api key from .env file\n",
    "load_dotenv()\n",
    "\n",
    "\n",
    "# define embedding function\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-base-en-v1.5\")\n",
    "\n",
    "# load vectorstore from disk (which was created in vectorstore.py)\n",
    "db2 = chromadb.PersistentClient(path=\"chroma_db\")\n",
    "chroma_collection = db2.get_or_create_collection(\"quickstart\")\n",
    "\n",
    "vector_store = ChromaVectorStore(chroma_collection=chroma_collection)\n",
    "index = VectorStoreIndex.from_vector_store(\n",
    "    vector_store,\n",
    "    embed_model=embed_model,\n",
    ")\n",
    "\n",
    "\n",
    "# Query Data from the persisted index (vectorstore)\n",
    "query_engine = index.as_query_engine()\n",
    "\n",
    "vectorstore_engine = QueryEngineTool(\n",
    "    query_engine=query_engine,\n",
    "    metadata=ToolMetadata(\n",
    "        name=\"document_search\",\n",
    "        description=\"Search for relevant information in the vectorstore\"\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Toolbox for the agent\n",
    "tools = [\n",
    "    note_engine,\n",
    "    vectorstore_engine\n",
    "]\n",
    "\n",
    "# Giving the agent the context for its role\n",
    "context = \"\"\"Purpose: The primary role of this agent is to assist users by providing accurate \n",
    "            information about transport concerns based on the data contained in vectorstore. \n",
    "            If he doesn't know he should not make up anything only answer \"I DON'T KNOW\" \"\"\"\n",
    "\n",
    "\n",
    "# Activate the agent\n",
    "llm = OpenAI(model=\"gpt-4o-mini\") # model can be adjusted\n",
    "agent = ReActAgent.from_tools(tools, llm = llm, verbose = True, context = context)      # sets everything up\n",
    "\n",
    "\n",
    "# Query it as long as you don't enter q\n",
    "while (prompt := input(\"Enter a prompt (q to quit): \")) != \"q\":\n",
    "    result = agent.query(prompt)\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Content of the outputed notes textfile:\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "[2024-11-23 22:40:58] Routes from Vienna to Italy: 1. Wien Freudenau Hafen CCT � border crossing\n",
    "Nickelsdorf (Hungary) 2. Wien Freudenau Hafen CCT � border crossing Klingenbach\n",
    "(Hungary) 3. Wien Freudenau Hafen CCT � border crossing Drasenhofen (Czechia)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
